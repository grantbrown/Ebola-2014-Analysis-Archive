
<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="icon" href="../../favicon.ico">

    <title>2014 Ebola Epidemic</title>
    <link href="./bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link href="./css/ebola.css" rel="stylesheet">
    
  </head>

  <body>
    <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
      <div class="container">
        <div class="navbar-header">
          <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
            <span class="icon-bar"></span>
          </button>
          <a class="navbar-brand" href="http://grantbrown.github.io/libspatialSEIR/">libspatialSEIR</a>
        </div>
        <div class="collapse navbar-collapse">
          <ul class="nav navbar-nav">
            <li><a href="#toc-section-anchor">TOC</a></li>
            <li><a href="http://en.wikipedia.org/wiki/Compartmental_models_in_epidemiology">Compartmental Models</a></li>
            <li><a href="http://en.wikipedia.org/wiki/2014_Guinea_Ebola_outbreak">More on the Outbreak</a></li>
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </div>
  
  
    <div id = "title-section" class = "container">
      <div class="row">
        <div class="col-sm-12">
          <h1>Estimating and Predicting Epidemic Behavior for the 2014 West African Ebola Outbreak</h1>
          <h4>A Quick Stochastic Spatial SEIR Modeling Approach</h4>
          <h5><a href="https://grantbrown.github.io">Grant Brown</a></h5>
          <h5><a href="http://www.public-health.uiowa.edu/people/jacob-oleson/">Jacob Oleson</a></h5>
          <h5>Last Updated:
<!--begin.rcode label="SaveDate", echo=FALSE, results='asis'
cat(as.character(Sys.Date()))
end.rcode-->
</h5>
        </div>
      </div>
    </div>
    <a id="toc-section-anchor" class="anchor"></a>
    <div id="toc-section" class="container">
      <h2>Table of Contents</h2>
      <div class = "row">
        <div class="col-sm-11 col-sm-offset-1">
          <ol>
            <li><a href="#introduction-sect">Introduction</a>
              <ul>
                <li><a href="#intro-abstract-sect">About This Document</li>
                <li><a href="#intro-outbreak-sect">The Outbreak</li>
                <li><a href="#intro-data-sect">The Data</li>
                <li><a href="#intro-compartment-sect">Compartmental Models</li>
              </ul>
            </li>
            <li><a href="#anchor-analysis-2-sect">Analysis</a>
              <ul>
                <li><a href="#analysis-2-set-up-sect">Set Up</a></li>
                <li><a href="#analysis-2-convergence-sect">Convergence Diagnosis</a></li>
                <li><a href="#analysis-2-r0-sect">Basic Reproductive Number</a></li>
                <li><a href="#analysis-2-prediction-sect">Prediction</a></li>
              </ul>
            </li>
            <li><a href="#conclusions-sect">Conclusions</a></li>
          </ol>
        </div>
      </div>
    </div>

    <div class="container">
      <a id="introduction-sect" class="anchor">
      <h2>Introduction</h2>
      </a>
      <div class="row">
        <div class = "col-sm-10 col-sm-offset-1">
          <a id="intro-abstract-sect" class="anchor">
          <h3>About this document.</h3>
          </a>
          <p>This is a living document, as the Ebola epidemic is rapidly evolving. Presented below is a preliminary modeling approach to the 
          crisis, originally conceived as an illustration of the spatial SEIR model family generally and the capabilities of the rapidly developing 
          (and totally unfinished) libspatialSEIR software library particularly. This is not yet peer reviewed research, or even a particularly complete analysis. 
          Nevertheless, we hope that the initial exploration given below is instructive and useful. </p>
          <br/>
          <p>
          Past versions of this analysis are cached in a repository on Github, and remain available: 
          <ul>
            <li><a href="http://grantbrown.github.io/Ebola-2014-Analysis-Archive/Sep_08_2014/Ebola2014/Ebola2014.html">Sep  8, 2014</a></li>
            <li><a href="http://grantbrown.github.io/Ebola-2014-Analysis-Archive/Aug_28_2014/Ebola2014/Ebola2014.html">Aug 28, 2014</a></li>
            <li><a href="http://grantbrown.github.io/Ebola-2014-Analysis-Archive/Aug_12_2014/Ebola2014/Ebola2014.html">Aug 12, 2014</a></li>
            <li><a href="http://grantbrown.github.io/Ebola-2014-Analysis-Archive/Aug_10_2014/Ebola2014/Ebola2014.html">Aug 10, 2014</a></li>
            <li><a href="http://grantbrown.github.io/Ebola-2014-Analysis-Archive/Aug_05_2014/Ebola2014/Ebola2014.html">Aug 5, 2014</a></li>
            <li><a href="http://grantbrown.github.io/Ebola-2014-Analysis-Archive/Aug_03_2014/Ebola2014/Ebola2014.html">Aug 3, 2014</a></li>
            <li><a href="http://grantbrown.github.io/Ebola-2014-Analysis-Archive/Jul_30_2014/Ebola2014/Ebola2014.html">Jul 30, 2014</a></li>
            <li><a href="http://grantbrown.github.io/Ebola-2014-Analysis-Archive/Jul_29_2014/Ebola2014/Ebola2014.html">Jul 29, 2014</a></li>
            <li><a href="http://grantbrown.github.io/Ebola-2014-Analysis-Archive/Jul_25_2014/Ebola2014/Ebola2014.html">Jul 25, 2014</a></li>
            <li><a href="http://grantbrown.github.io/Ebola-2014-Analysis-Archive/Jul_24_2014/Ebola2014/Ebola2014.html">Jul 25, 2014</a></li>
          <ul>
          
          <p>Additional analyses are underway. An <a href = "http://grantbrown.github.io/libspatialSEIR/doc/tutorials/Ebola2014/Ebola2014_PastPred.html">informal look at prediction performance over time</a> is also available.</p>
        </div>
        <div class="col-sm-1"></div>
        <br/>
        <div class = "col-sm-10 col-sm-offset-1">
          <a id="intro-abstract-sect" class="anchor">
          <h3>Summary of Recent Changes</h3>
          </a>
          <ul>
            <li><strong>Oct 2</strong> There have been a lot of changes for this release. The temporal component was dramatically simplified, so we're fitting a baseline SEIR model with a different intensity parameter for each nation. In addition, the spatial structure was generalized to allow a separate mixing parameter for each pair of countries. Finally, three different methods of calculating R0 are compared, and a lot of behind the scenes changes to libspatialSEIR and the R API took place. Upcoming changes include the introduction of "hybrid" samplers which may help deal with some of the autocorrelation, seen for example in the E to I transition probability chains. Despite the model changes, we continue to see a dramatic and prolonged predicted increase in cases.  </li>
            <li><strong>Sep 8</strong> Fixed R0 calculations, which were showing the per-report R0 components, but didn't account for infection length. They have now been appropriately integrated over time.</li>
            <li><strong>Sep 4</strong> The situation continues to worsen, which is especially worrying given that the data used are almost certainly undercounts. Removed the polynomial analysis in favor of the spline basis analysis to save on computation time. </li>
            <li><strong>Aug 31</strong> Basic reproductive number clearly very heterogenous between countries. Other interpretations TBD.</li>
            <li><strong>Aug 28</strong> With the addition of Nigeria and new data, the situation appears dire across the board, especially in Liberia. The basic reproductive number calculations no longer look reasonable, so more must be done to estimate them separately for each country. The changes may also be due to recent changes to the R0 estimation code, which must now be reevaluated. This work is underway. </li>
            <li><strong>Aug 12</strong> Liberia continues to worsen, though Sierra Leone appears to have leveled off. Guinea might be worsening slightly. </li>
            <li><strong>Aug 10</strong> Predictions remain much the same, though perhaps not so immediately catestrophic as the August 5 predictions. </li>
            <li><Strong>Aug 5</strong> Models begin to show catastrophic predictions. Epidemic is changing too quickly for these simple models.</li>
            <ul>
              <li>Shorten prediction window</li>
              <li>Increase intensity process flexibility (quartic rather than cubic)</li>
              <li>Recall that these models can't account for changing inteventions, of which there are many. The predictions are therefore made
              under the assumption that the epidemic will continue to evolve according to the same process it has so far.</li>
            </ul>
            <li><Strong>Aug 3</strong> Predicted epidmic curves start to strongly favor a uniformly worsening situation.</li>
            <li><Strong>July 30</strong> Previous predictions of mid-fall resolution of epidemic begin to shift.</li>
          </ul>
        </div>
        <div class="col-sm-1"></div>
        
        
        <div class = "col-sm-10 col-sm-offset-1">
        <a id="intro-outbreak-sect" class="anchor">
        <h3>The Outbreak</h3>
        </a>
          <p>
          The 2014 Ebola outbreak in West Africa is an ongoing public health crisis, which has killed thousands of people so far. The cross-border nature of this epidemic, which emerged in Guinea, Liberia and Sierra Leone has complicated mitigation efforts, as has the poor health infrastructure in the region. This document explores a simple spatial SEIR model to make some initial predictions. 
          </p>
          <a id="intro-data-sect" class="anchor">
        <h3>The Data</h3>
        </a>
        <p>
        A summary of the WHO case reports is very helpfully compiled on wikipedia. It can be easily read into R with the xml library: 
      </p>
<button class="btn btn-default code-button">Show/Hide Code Block</button>
<div class="code-and-output-block" style="display:none">
<!--begin.rcode label="LoadPackagesReadData"
library(knitr)
library(coda) # Load the coda library for MCMC convergence diagnosis
library(spatialSEIR)
library(XML) # Load the XML library to read in data from Wikipedia
library(parallel) # Load the parallel library to enable multiple chains to be run simultaneously. 

## Define Document Compilation Parameters

#documentCompilationMode = "release"
documentCompilationMode = "debug"
# How many degrees of freedom should the fit have?
modelDF = 3
# if modelDF != 0, should spline basis be knot based or DF based?
# Option1: "Knots"
# Option2: "DF"
modelMode = "DF"
# How far into the future do we want to make predictions?
pred.days = 120


## Compute number of samples/batches
numBurnInBatches =      ifelse(documentCompilationMode == "release", 1000,  1000)
convergenceCriterion =  ifelse(documentCompilationMode == "release", 1.2,  5)
convergenceSampleSize =  ifelse(documentCompilationMode == "release", 100000, 10000) 
convergenceBatchSize =  ifelse(documentCompilationMode == "release", 100000, 10000) 
minimumSamples =         ifelse(documentCompilationMode == "release", 3000000, 50000) 
extraR0Iterations =     ifelse(documentCompilationMode == "release", 500,   50)
extraR0BatchSize =     ifelse(documentCompilationMode == "release", 1000,   1000)
iterationStride =       ifelse(documentCompilationMode == "release", 1000,   100)
targetDaysPerRecord = 7
totalSamples = 0

## Read in the data

dat = read.csv("../../Data/ebola/country_timeseries.csv")[,c(1, 3,4,5)]

charDate = as.character(dat[,1])

rptDate = as.Date(charDate, "%m/%d/%Y")
numDays = max(rptDate) - min(rptDate)
numDays.pred = numDays + pred.days

original.rptDate = rptDate
ascendingOrder = order(rptDate)
rptDate = rptDate[ascendingOrder]
original.rptDate = original.rptDate[ascendingOrder]


cleanData = function(dataColumn, ascendingOrder)
{
    # Remove commas
    charCol = as.character(dataColumn)[ascendingOrder]

    if (is.na(charCol[1]))
    {
      charCol[1] = "0"
    }
    charCol = as.numeric(charCol)
    
    for (i in 2:length(charCol))
    {
      if (is.na(charCol[i]))
      {
        charCol[i] = charCol[i-1]  
      }
    }
    # charCol
    # Correct for undercounts
    for (i in seq(length(charCol), 2))
    {
        if (charCol[i-1] > charCol[i])
        {
            charCol[i-1] = charCol[i]
        }
    }
    charCol
}

Guinea = cleanData(dat[,2], ascendingOrder)
Liberia = cleanData(dat[,3], ascendingOrder)
Sierra.Leone = cleanData(dat[,4], ascendingOrder)
rawData = cbind(Guinea, Sierra.Leone, Liberia)
rownames(rawData) = as.character(original.rptDate)
colnames(rawData) = paste(paste("&nbsp;&nbsp;", c("Guinea", "Liberia", "Sierra Leone")), "&nbsp;&nbsp;")

# The data needs to be aggregated: there's some error in the measurements, 
# and we're not actually observing infection times. The data is therefore
# recorded at an artifically high time scale.
uncumulate = function(x)
{
    out = c(x[2:length(x)]-x[1:(length(x)-1)])
    ifelse(out >= 0, out, 0)
}
nDays = uncumulate(original.rptDate)

thinIndices = function(minDays, weights)
{
    keepIdx = c(length(weights))
    currentWeight = 0
    lastIdx = -1
    for (i in seq(length(weights)-1, 1))
    {
      currentWeight = currentWeight + weights[i]
      if (currentWeight >= minDays)
      {
          currentWeight = 0
          keepIdx = c(keepIdx, i)
          lastIdx = i
      }
    }
    if (currentWeight != 0)
    {
      keepIdx = c(keepIdx, lastIdx-1)
    }
    keepIdx
}

keepIdx = thinIndices(targetDaysPerRecord, c(nDays,1))
keepIdx = keepIdx[order(keepIdx)]



# Define the plot for the next section
ylim = c(min(c(Guinea, Sierra.Leone, Liberia)), 
             max(c(Guinea, Sierra.Leone, Liberia)))
figure1 = function()
{
      plot(original.rptDate, Guinea, type = "l", 
           main = "Raw Data: Case Counts From Wikipedia", 
           xlab = "Date", 
           ylab = "Total Cases",
           ylim = ylim, lwd = 3)
      abline(h = seq(0,100000, 100), lty = 2, col = "lightgrey")
      lines(original.rptDate, Liberia, lwd = 3, col = "blue", lty = 2)
      lines(original.rptDate, Sierra.Leone, lwd = 3, col = "red", lty = 3)
      
      legend(x = original.rptDate[1], y = max(ylim), legend = 
               c("Guinea", "Liberia", "Sierra Leone"), 
             lty = 1:3, col = c("black", "blue","red"), bg="white", cex = 1.1,
             lwd=3)
}


Guinea = Guinea[keepIdx]
Sierra.Leone = Sierra.Leone[keepIdx]
Liberia = Liberia[keepIdx]

original.rptDate = original.rptDate[keepIdx]
rptDate = original.rptDate[2:length(original.rptDate)]
end.rcode-->
</div>
<p>
With data in hand, let's begin where every analysis should begin: graphs.
</p>

<!--begin.rcode label="PlotFig1", dpi=150, fig.align='center', echo=FALSE
figure1()
end.rcode-->
<p>
  In addition to the above graph, the raw data is archived for posterity in the code block below. Wikipedia changes a lot, so it's important 
  to record the context of the results presented here. 
</p>
<button class="btn btn-default code-button">Show/Hide Code Block</button>
<div class="code-and-output-block" style="display:none">
<!--begin.rcode label="SaveTable", fig.align='center', results='asis'
kable(rawData)
end.rcode-->
</div>
<p>
This graph and corresponding table represent cumulative counts, but because case reports can be revised downward due to non-Ebola illnesses the graphs are not strictly monotone. A quick, but effective solution to this problem is to simply "un-cumulate" the data and bound it at zero to get a rough estimate of new case counts over time. 
<br/>
</p>
<button class="btn btn-default code-button">Show/Hide Code Block</button>
<div class="code-and-output-block" style="display:none">
<!--begin.rcode label="CreateDataset"

# The "I_star" name will make more sense in a bit
I_star = cbind(uncumulate(Guinea), 
               uncumulate(Liberia), 
               uncumulate(Sierra.Leone))
I0 = c(Guinea[1], Liberia[1], Sierra.Leone[1])

# Define the temporal offset vector to be the number of days reflected in each 
# aggregated record (time between reports).
offsets = uncumulate(original.rptDate)
if (any(offsets <= 0))
{
    cat("Invalid Date Information. The data source has likely changed.\n")
    stop(-1)
}

InfectionPerDay = I_star/(cbind(offsets, offsets, offsets))

# Define figure 2 for next section

figure2 = function()
{
    ylim = c(0,max(InfectionPerDay)*1.2)
    layout(matrix(c(1,2), nrow = 1),
        widths = c(8,4), heights = c(4,4))
    plot(rptDate, InfectionPerDay[,1], main = "Crude Guess at New Case Counts Per Day", 
         xlab = "Date", 
         ylab = "New Cases",
         lty=1, lwd = 2,
         ylim = ylim, type = "l"
         )
    abline(h = seq(0, 1000, 10), lty = 2, col = "lightgrey")
    lines(rptDate, InfectionPerDay[,2], col = "blue",lty=2, lwd = 2)
    lines(rptDate, InfectionPerDay[,3], col = "red", lty = 3, lwd = 2)
    par(xaxt="n")
    par(yaxt="n")
    par(bty="n")
    par(xpd=TRUE)
    plot(c(0,10),c(0,10), type = "n", main  ="",xlab="",ylab="")
    legend(x=-2,y=10, legend = c("Guinea", "Liberia", "Sierra Leone"), lty = 1:3,lwd=2, 
           col = c("black", "blue", "red"))
    par(xpd=FALSE)
    par(xaxt="s")
    par(yaxt="s")
    par(bty="o")
}
end.rcode-->
</div>


<p>
  For better graphical representation, the "un-cumulated" counts are scaled to represent average number of infections per day, and linearly interpolated. The process is a bit noisier from this perspective when compared to the original cumulative counts.  
</p>

<!--begin.rcode label="PlotFigure2", dpi=150,fig.align='center',echo=FALSE
  figure2()
end.rcode-->

<br/>

One can also represent this data geographically to get an idea of the spatial epidemic pattern, and to place the problem in a more relatable context. 

<h4 align=center>Average Number of Infections Per Day:</h4>
<!--begin.rcode label="MakeMap1", echo=FALSE
# From here on we'll use the aggregated data. 

maxIdx = nrow(I_star)

library(rCharts)
library(stats)

x = rptDate - min(rptDate)
guinea.interp = approx(x,InfectionPerDay[,1],xout = 0:max(x))
liberia.interp = approx(x,InfectionPerDay[,2],xout = 0:max(x))
sierraleone.interp = approx(x,InfectionPerDay[,3],xout = 0:max(x))



interpMatrix = cbind(guinea.interp$y, liberia.interp$y,sierraleone.interp$y)
cutvals = cut(interpMatrix, breaks = 9)
interpMatrix.cut = matrix(as.numeric(cutvals), nrow = nrow(interpMatrix))


upperVals = as.numeric(lapply(strsplit(c(gsub("[(]", "", gsub("]", "", unique(as.character(cutvals))))), ","), function(x){return(x[2])}))
upperVals = round(upperVals[order(upperVals)],0)


hcol = c("#ffffef", "#fff7bf", "#fee39f", "#fec45f", "#fe993f", "#ec702f", "#cc4c1f", "#993402", "#662520")
color.palette = c(hcol[1],hcol)
fills = setNames(color.palette, c("defaultFill", paste("lt", upperVals, sep = "")))


# GIN, LBR, SLE, 
outList = list()
for (tpt in min(x):max(x))
{
    outList[[as.character(tpt+1)]] = list("GIN" = list("fillKey"=factor(paste("lt", upperVals[interpMatrix.cut[tpt+1,1]], sep =""), 
                                                        levels = names(fills))),
                                          "LBR" = list("fillKey"=factor(paste("lt", upperVals[interpMatrix.cut[tpt+1,2]], sep = ""), 
                                                        levels = names(fills))),
                                          "SLE" = list("fillKey"=factor(paste("lt",upperVals[interpMatrix.cut[tpt+1,3]], sep = ""), 
                                                        levels = names(fills))))
}

end.rcode-->


<div class='container' ng-app="data_app" ng-controller='rChartsCtrl' id ="zoom_map_container" style="position: relative; max-width: 100%; height:100%">
  <div class = "row">
    <div class="col-sm-3">
      <input id='zoom-map-slider' type='range' min=1 max=
<!--begin.rcode echo=FALSE, results='asis'
cat(numDays)
end.rcode--> 
      ng-model='Day' width=200>
       <span>Day: <span id ="zoom-map-day-counter"></span></span>
    </div>
    <div class="col-sm-1">  <button class="btn btn-mini btn-primary" id="zoom-map-play" type="button">Play</button></div>
    <div class = "col-sm-6"></div>
  </div>
  <div class="row">
    <div id='zoom_map' class='rChart datamaps col-sm-8 col-sm-offset-1' style="position: relative; max-width: 100%; height:100%"></div>  
    <div class="col-sm-3"></div>
  </div>
</div>
<br/>
<br/>

      <a id="intro-compartment-sect" class="anchor">
      <h3>Compartmental Models</h3>
      </a>
      <p>
        Now that the data is read in (and now that we have several plots to suggest that we haven't done anything too terribly stupid with it)
        , let's do some compartmental epidemic modeling. Not only has Ebola been <a href="http://www.ncbi.nlm.nih.gov/pubmed/17156292">well modeled in the past</a> using compartmental modeling techniques, but this author happens to be working on a software library designed to fit compartmental models in the spatial SEIRS family. What a strange coincidence! Specifically, we'll be using heirarchical Bayesian estimation methods to fit a spatial SEIR model to the data.  
        </p>
        <br/>
        <br/>
        <p>
        While a full treatment of this field of epidemic modeling is (far) beyond the scope of this writing, the basic idea is pretty intuitive. In order to come up with a simplified model of a disease process, discrete disease states (aka, compartments) are defined. The most common of these are S, E, I, and R which stand for:<br>
      </p>
      <ul>
        <li><strong>S</strong>usceptible to a particular disease</li>
        <li><strong>E</strong>xposed and infected, but not yet infectious</li>
        <li><strong>I</strong>nfectious and capable of transmitting the disease</li>
        <li><strong>R</strong>emoved or recovered</li>
      </ul>
  <p>
    This sequence, traversed by members of a population (S to E to I to R), forms what we might call the temporal process model of our analysis. This analysis belongs to the stochastic branch of the compartmental modeling family, which has its roots in deterministic systems of ordinary and partial differential equations. In the stochastic framework, transitions between the compartments occur according to unknown probabilities. It is the S to E probability, which captures infection activity, into which we introduce spatial structure. Some details of this are given as comments to the code below, and more information than you probably want on the statistical particulars is available in <a href="https://github.com/grantbrown/libspatialSEIR/blob/master/doc/models/Ebola2014Analysis.pdf">this pdf document</a>. For now, suffice it to say that we'll place a simple spatial structure on the epidemic process which simply allows disease to spread between the three nations involved, and we'll try to estimate the strength of that relationship. Many other potential structures are possible, limited primarily by the amount of additional research and data compilation one is willing to do. </p><br/><br/>
<p>
For the purposes of this analysis, we will not do anything fancy with demographic information or public health intervention dates. Demographic parameters are relatively difficult to estimate here, as there are only four spatial units which are all from the same region. Intervention dates are more promising, but their inclusion requires much more background research than we have time for here. In the interest of simplicity and estimability, we'll just fit a different disease intensity parameter for each of the three countries to capture aggregate differences in Ebola susceptibility in addition to using a set of basis functions to capture the 
temporal trend. 
  </p>
    </div>
    <div class="col-sm-1">
    </div>
  </div>
    <div class="row">
    <div class = "col-sm-10 col-sm-offset-1">
    <!-- Polynomial analysis removed -->
    </div>
    <div class="col-sm-1"></div>
  </div>
<br/><br/>
 
  <a id="anchor-analysis-2-sect" class = "anchor">
  <h2>Analysis</h2> </a>
  
  <div class="row">
    <div class = "col-sm-10 col-sm-offset-1">
      <a id="analysis-2-set-up-sect" class="anchor"><h3>Set Up</h3></a>
  <p>
    There are some things we need to define before we can start fitting models and making predictions. 
  </p>
  <ol>
    <li>The population sizes need to be determined.</li>
    <li>Initial values for the four compartments must be determined.</li>
    <li>The time points are not evenly spaced, so we need to define appropriate offset values to capture the amount of aggregation performed (time between reports).</li>
    <li>We must define the spatial correlation structure.</li>
    <li>(optionally) A set of basis functions to capture the temporal trend.</li>
    <li>Prior parameters and parameter staring values must be specified for each <a href="http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo">chain.</a></li>
    <li>A whole bunch of bookkeeping stuff for which I haven't yet programmed sensible default behavior needs to be set up.</li>
  </ol>
  <p>
  Compartment starting values follow the usual convention of letting the entire initial population be divided into susceptibles and infectious individuals. The starting value for the number of infectious individuals was 86 for Guinea and zero for the other nations. Temporal offsets are actually calculated in the first code block (above) as the differences between the report times. For temporal basis functions, several options have been explored over the life of this project, including orthogonal polynomial and natural splines. The current analysis uses no temporal basis function, instead choosing to increase the granularity of the spatial correlation structure. Future work will introduce time varying intervention terms to quantify the effects of the early efforts of MSF and the ongoing international response.  Prior parameters for the E to I and I to R transitions were chosen based on well documented values for the average latent and infectious times, and the rest of the prior parameters were left vague. These decisions are addressed in more detail as comments to the code below. 
  </p>
  <br/>
  <br/>
  
<button class="btn btn-default code-button">Show/Hide Code Block</button>
      <div class="code-and-output-block" style="display:none">
<!--begin.rcode label="BuildVariables"
library(splines)
# Guinea, Liberia, Sierra Leone, Nigeria
N = matrix(c(10057975, 4128572, 6190280), nrow = nrow(I_star),ncol = 3, 
           byrow=TRUE)
X = diag(ncol(N))
X.predict = X

daysSinceJan = as.numeric(rptDate - as.Date("2014-01-01"))
daysSinceJan.predict = c(max(daysSinceJan) + 1, max(daysSinceJan) 
                         + seq(2,pred.days-2,2))
{
if (modelDF != 0 && modelMode == "DF")
{
  splineBasis = ns(daysSinceJan, df = modelDF)
  splineBasis.predict = predict(splineBasis, daysSinceJan.predict)
  Z = matrix(splineBasis, ncol = modelDF)
  Z.predict = splineBasis.predict
  # These co-variates are the same for each spatial location, 
  # so duplicate them row-wise. 
  Z = Z[rep(1:nrow(Z), nrow(X)),,drop=FALSE]
  Z.predict = Z.predict[rep(1:nrow(Z.predict), nrow(X)),,drop=FALSE]
  
  # For convenience, let's combine X and Z for prediction.
  X.pred = cbind(X.predict[rep(1:nrow(X.predict), 
                               each = nrow(Z.predict)/nrow(X)),], Z.predict)
}
else if (modelDF != 0 && modelMode == "Knots")
{
  splineBasis = ns(daysSinceJan, knots = floor(quantile(daysSinceJan, 
                                                        seq(0,1, length = modelDF)))[1:(modelDF-1)])
  splineBasis.predict = predict(splineBasis, daysSinceJan.predict)
  Z = matrix(splineBasis, ncol = modelDF)
  Z.predict = splineBasis.predict
  # These co-variates are the same for each spatial location, 
  # so duplicate them row-wise. 
  Z = Z[rep(1:nrow(Z), nrow(X)),,drop=FALSE]
  Z.predict = Z.predict[rep(1:nrow(Z.predict), nrow(X)),,drop=FALSE]
  
  # For convenience, let's combine X and Z for prediction.
  X.pred = cbind(X.predict[rep(1:nrow(X.predict), 
                               each = nrow(Z.predict)/nrow(X)),], Z.predict)
}
else
{
  splineBasis = c()
  splineBasis.predict = c()
  Z = NA
  Z.predict = NA
  X.pred = cbind(X.predict[rep(1:nrow(X.predict), each = length(daysSinceJan.predict)),])
}
}
DM1 = matrix(c(0,1,0,
               1,0,0,
               0,0,0), nrow = 3, ncol = 3, byrow = TRUE)
DM2 = matrix(c(0,0,1,
               0,0,0,
               1,0,0), nrow = 3, ncol = 3, byrow = TRUE)
DM3 = matrix(c(0,0,0,
               0,0,1,
               0,1,0), nrow = 3, ncol = 3, byrow = TRUE)
dmList = list(DM1, DM2, DM3)


# Define prediction offsets. 
offset.pred = uncumulate(c(1,seq(2,pred.days-2,2)))


# There's no reinfection process for Ebola, but we still need to provide dummy
# values for the reinfection terms. This will be changed (along with most of 
# the R level API) Dummy covariate matrix:
X_p_rs = matrix(0)

# Dummy value for reinfection params
beta_p_rs = rep(0, ncol(X_p_rs))
# Dummy value for reinfection params prior precision
betaPrsPriorPrecision = 0.5


    
# Declare prior parameters for the E to I and I to R probabilities. 

# Latent period between 1 and 21 days
prior_gamma_ei = 1/5
prior_gamma_ir = 1/7
transitionEffectiveSampleSizes = 10000
hist(rgeom(rep(1, 100000), 1-exp(-prior_gamma_ei)), xlab = "Days",
     main = "Prior Distribution\n Ebola Latent Period", freq=FALSE)

hist(rgeom(rep(1, 100000), 1-exp(-prior_gamma_ir)), xlab = "Days",
     main = "Prior Distribution\n Ebola Infectious Period", freq=FALSE)

# Declare prior parameters for the overdispersion precision
priorAlpha_phi = 10000
priorBeta_phi = 1500

# Declare prior precision for exposure model paramters
betaPriorPrecision = 0.1

# Declare a function which can come up with several different starting values 
# for the model parameters. This will allow us to assess convergence. 
proposeParameters = function(seedVal, chainNumber)
{
    set.seed(seedVal) 
    
    # 2 to 21 day incubation period according to who
    p_ei = 0.25 + rnorm(1, 0, 0.02) 
    # Up to 7 weeks even after recovery
    p_ir = 0.14 + rnorm(1, 0, 0.01) 
    gamma_ei=-log(1-p_ei)
    gamma_ir=-log(1-p_ir)
      
    # Starting value for exposure regression parameters
    beta = rep(0, ncol(X) + ifelse(all(is.na(Z)), 0, ncol(Z)))
    beta[1:(ncol(X))] = rnorm(ncol(X), -3, 3)
    #beta[1] = 2.5 + rnorm(1,0,0.5)
    
    phi = 0.01 # Overdispersion precision
    
    outFileName = paste("./chain_output_ebola_", chainNumber ,".txt", sep = "")
    
    # Make a crude guess as to the true compartments:
    # S_star, E_star, R_star, and thus S,E,I and R
    DataModel = buildDataModel(I_star, type = "overdispersion", 
                               params=c(priorAlpha_phi,priorBeta_phi))
    ExposureModel = buildExposureModel(X, Z, beta, betaPriorPrecision, offsets, nTpt = nrow(I_star))
    ReinfectionModel = buildReinfectionModel("SEIR")
    SamplingControl = buildSamplingControl(iterationStride=iterationStride,
                                           sliceWidths=c(1, # S_star
                                                         1, # E_star
                                                         1,  # R_star
                                                         1,  # S_0
                                                         1,  # I_0
                                                         0.05,  # beta
                                                         0.0,  # beta_p_rs, fixed in this case
                                                         0.01, # rho
                                                         0.01, # gamma_ei
                                                         0.01,  # gamma_ir
                                                         0.01)) # phi)
    
    InitContainer = buildInitialValueContainer(I_star, N, 
                                               S0 = N[1,]-I_star[1,] - 2*I0,
                                               E0 = I0,
                                               I0 = I0)
    DistanceModel = buildDistanceModel(dmList, priorAlpha = 1, priorBeta = 500)
    TransitionPriors = buildTransitionPriorsFromProbabilities(1-exp(-prior_gamma_ei), 1-exp(-prior_gamma_ir),
                                                              transitionEffectiveSampleSizes, transitionEffectiveSampleSizes)
    return(list(DataModel=DataModel,
                ExposureModel=ExposureModel,
                ReinfectionModel=ReinfectionModel,
                SamplingControl=SamplingControl,
                InitContainer=InitContainer,
                DistanceModel=DistanceModel,
                TransitionPriors=TransitionPriors,
                outFileName=outFileName))
}

end.rcode-->
      </div>
  
  
<p>
  With the set up out of the way, we can finally build and run the models the models. The code presented below has recently (8/27/2014) been set up to use the "parallel" library which is included with the R statistical analysis software. While this allows us to spend considerably less time waiting for the document to compile, the code may be more difficult to understand for those unfamiliar with this useful parallelization library. The previous analyses, linked above, may be a better guide to the basic use of the spatialSEIR library for such users. 
</p>
<br/>  
  
<button class="btn btn-default code-button">Show/Hide Code Block</button>
      <div class="code-and-output-block" style="display:none">
<!--begin.rcode label="BuildAndRunModel"


paramsList = list(list("estimateR0"=FALSE, "traceCompartments"=TRUE, "seedVal"=133,"chainNumber"=4),
                  list("estimateR0"=TRUE, "traceCompartments"=FALSE, "seedVal"=1224,"chainNumber"=5),
                  list("estimateR0"=FALSE,"traceCompartments"=FALSE, "seedVal"=12325,"chainNumber"=6))

buildAndBurnInModel = function(params)
{
  library(spatialSEIR)
  # save proposal and params to node workspace
  proposal <<- proposeParameters(params[["seedVal"]], params[["chainNumber"]])
  params <<- params
  SEIRmodel =  buildSEIRModel(proposal$outFileName,
                              proposal$DataModel,
                              proposal$ExposureModel,
                              proposal$ReinfectionModel,
                              proposal$DistanceModel,
                              proposal$TransitionPriors,
                              proposal$InitContainer,
                              proposal$SamplingControl)
  
  SEIRmodel$setRandomSeed(params[["seedVal"]])
  # Save model object to node workspace
  localModelObject <<- SEIRmodel
 
  # Do we need to keep track of compartment values for prediction? 
  # No sense doing this for all of the chains.
  if (params[["traceCompartments"]])
  {
    SEIRmodel$setTrace(0) #Guinea 
    SEIRmodel$setTrace(1) #Liberia
    SEIRmodel$setTrace(2) #Sierra Leone
  }
      
  # Make a helper function to run each chain, as well as update the metropolis 
  # tuning parameters. 
  runSimulation = function(modelObject,
                           numBatches=500, 
                           batchSize=20, 
                           targetAcceptanceRatio=0.2,
                           tolerance=0.05,
                           proportionChange = 0.1
                          )
  {
      for (batch in 1:numBatches)
      {
          modelObject$simulate(batchSize)
          modelObject$updateSamplingParameters(targetAcceptanceRatio, 
                                               tolerance, 
                                               proportionChange)
      }
  }

  # Burn in tuning parameters
  runSimulation(SEIRmodel, numBatches = numBurnInBatches)
  runSimulation(SEIRmodel, batchSize = 100, numBatches = numBurnInBatches)
  
  SEIRmodel$compartmentSamplingMode = 17
  SEIRmodel$performHybridStep = 10
  if (modelDF > 0)
  {
      SEIRmodel$useDecorrelation = 10
  }
}


finishSimulation = function(iterationNumber)
{
  dat = read.csv(proposal$outFileName)
  
  ## Do we need to estimate R0 for this chain?
  if (params[["estimateR0"]])
  {  
    R0 = array(0, dim = c(nrow(I_star), ncol(I_star), extraR0Iterations))
    effectiveR0 = array(0, dim = c(nrow(I_star), ncol(I_star), extraR0Iterations))
    empiricalR0 = array(0, dim = c(nrow(I_star), ncol(I_star), extraR0Iterations))
    for (i in 1:extraR0Iterations)
    {
        localModelObject$simulate(extraR0BatchSize)
        for (j in 0:(nrow(I_star)-1))
        {
            R0[j,,i] = localModelObject$estimateR0(j)
            effectiveR0[j,,i] = localModelObject$estimateEffectiveR0(j)
            empiricalR0[j,,i] = apply(localModelObject$getIntegratedGenerationMatrix(j), 1, sum)
        }
    }
    
    R0Mean = apply(R0, 1:2, mean)
    R0LB = apply(R0, 1:2, quantile, probs = 0.05)
    R0UB = apply(R0, 1:2, quantile, probs = 0.95)
    effectiveR0Mean = apply(effectiveR0, 1:2, mean)
    effectiveR0LB = apply(effectiveR0, 1:2, quantile, probs = 0.05)
    effectiveR0UB = apply(effectiveR0, 1:2, quantile, probs = 0.95)
    empiricalR0Mean = apply(empiricalR0, 1:2, mean)
    empiricalR0LB = apply(empiricalR0, 1:2, quantile, probs = 0.05)
    empiricalR0UB = apply(empiricalR0, 1:2, quantile, probs = 0.95)
    orig.R0 = R0
    R0 = list("R0" = list("mean"=R0Mean, "LB" = R0LB, "UB" = R0UB),
              "effectiveR0" = list("mean"=effectiveR0Mean, "LB" = effectiveR0LB, 
                                   "UB" = effectiveR0UB),
              "empiricalR0" = list("mean"=empiricalR0Mean, "LB" = empiricalR0LB, 
                                   "UB" = empiricalR0UB))
  } else
  {
     R0 = NULL
     orig.R0 = NULL
  }  
  
  return(list("chainOutput" = dat, "R0" = R0, "rawSamples" = orig.R0))
}


cl = makeCluster(3, outfile = "err.txt")
clusterExport(cl, c( "offsets",
                     "X",
                     "Z",
                     "I0",
                     "X_p_rs",
                     "prior_gamma_ei",
                     "prior_gamma_ir",
                     "transitionEffectiveSampleSizes",
                     "priorAlpha_phi",
                     "priorBeta_phi",
                     "betaPriorPrecision",
                     "beta_p_rs",
                     "betaPrsPriorPrecision",
                     "N",
                     "dmList",
                     "iterationStride",
                     "proposeParameters",
                     "generateCompartmentProposal",
                     "extraR0Iterations",
                     "extraR0BatchSize",
                     "I_star",
                     "modelDF",
                     "numBurnInBatches"))


additionalIterations = function(params)
{
    
    N = params[[1]]
    batchSize = params[[2]]
    targetRatio = params[[3]]
    targetWidth=params[[4]]
    proportionChange = params[[5]]
    updateParameters = params[[6]]
    for (i in 1:(N/batchSize))
    {
        localModelObject$simulate(batchSize)
        if (updateParameters)
        {
            localModelObject$updateSamplingParameters(targetRatio, targetWidth, proportionChange)
        }
    }
}


iterationParams = list(convergenceSampleSize, convergenceBatchSize,
                       targetAcceptanceRatio=0.2,   
                       tolerance=0.05,
                       proportionChange = 0.1,
                       updateSamplingParams = FALSE)
iterationParams = list(iterationParams, iterationParams, iterationParams)
fileNames = paste(paste("chain_output_ebola_", c(paramsList[[1]]$chainNumber,
                        paramsList[[2]]$chainNumber,
                        paramsList[[3]]$chainNumber), sep = ""), ".txt", sep = "")                      
chains = parLapply(cl, paramsList, buildAndBurnInModel)

conv = FALSE
while (!conv)
{
    cat(paste("Not converged, adding iterations. Total so far: ", totalSamples, 
              "\n", sep =""))
    parLapply(cl, iterationParams, additionalIterations)
    totalSamples = totalSamples + convergenceSampleSize
    conv = checkConvergence(fileNames[1], fileNames[2], fileNames[3], maxVal = convergenceCriterion)
    conv = (conv && (minimumSamples < totalSamples))
}
cat("Chains converged, finishing up...\n")

cleanUpParamsList = list(1,2,3)
chains = parLapply(cl, cleanUpParamsList, finishSimulation)
save("chains", file="./chainOutput.Robj")
stopCluster(cl)

chain1 = chains[[1]]$chainOutput 
chain2 = chains[[2]]$chainOutput 
chain3 = chains[[3]]$chainOutput 


plotChains = function(c1, c2, c3, main)
{
    idx = floor(length(c1)/2):length(c1)
    mcl = mcmc.list(as.mcmc(c1),
                    as.mcmc(c2),
                    as.mcmc(c3))
    g.d = gelman.diag(mcl)
    main = paste(main, "\n", "Gelman Convergence Diagnostic and UL: \n",
                 round(g.d[[1]][1],2), ", ", round(g.d[[1]][2],2))
    
    plot(chain1$Iteration[idx], c1[idx], type = "l", main = main,
         xlab = "Iteration", ylab = "value", col = rgb(0,0,0,0.5))
    points(chain1$Iteration[idx], c1[idx], cex = 0.5, col=rgb(0,0,0,0.5))
  
    lines(chain2$Iteration[idx],c2[idx], col = rgb(0.5,1,0.2,0.5), lwd = 2)
    points(chain2$Iteration[idx], c2[idx], cex = 0.5, col=rgb(0.5,1,0.2,0.5))
  
    lines(chain3$Iteration[idx],c3[idx], col = rgb(0,0,1, 0.5), lwd = 2)
    points(chain3$Iteration[idx], c3[idx], cex = 0.5, col=rgb(0,0,1,0.5))
}


figure8 = function()
{
  par(mfrow = c(2,2))
  plotChains(chain1$BetaP_SE_0,
             chain2$BetaP_SE_0,
             chain3$BetaP_SE_0, 
             "Guinea Exposure Intercept")
  plotChains(chain1$BetaP_SE_1,
             chain2$BetaP_SE_1,
             chain3$BetaP_SE_1, 
             "Liberia Exposure Intercept")
  plotChains(chain1$BetaP_SE_2,
             chain2$BetaP_SE_2,
             chain3$BetaP_SE_2, 
             "Sierra Leone Exposure Intercept")
}

figure8_5 = function()
{
  if (any(is.na(Z))){return()}
  for (i in ncol(X):(ncol(X) + ncol(Z)-1))
  {
      plotChains(chain1[[paste("BetaP_SE_", i, sep = "")]],
                 chain2[[paste("BetaP_SE_", i, sep = "")]],
                 chain3[[paste("BetaP_SE_", i, sep = "")]],
                 paste("Temporal Basis Parameter ", i-ncol(X)+1, sep = ""))
  }
}

figure9 = function()
{
  par(mfrow = c(2,1))
  plotChains(1-exp(-chain1$gamma_ei),
             1-exp(-chain2$gamma_ei),
             1-exp(-chain3$gamma_ei)
             , "E to I Transition Probability")
  plotChains(1-exp(-chain1$gamma_ir),
             1-exp(-chain2$gamma_ir),
             1-exp(-chain3$gamma_ir)
             , "I to R Transition Probability")
}

figure9_5 = function()
{
  #par(mfrow = c(length(dmList), 1))
  for (i in 1:length(dmList))
  {
      plotChains(chain1[[paste("rho_", i-1, sep = "")]],
                 chain2[[paste("rho_", i-1, sep = "")]],
                 chain3[[paste("rho_", i-1, sep = "")]],
                 paste("Spatial Parameter ", i, sep = "")
                 )
  }
}

## Parameter Estimates 

nbeta = ncol(X) + ifelse(class(Z) == "matrix", ncol(Z), 0)
c1 = chain1[floor(nrow(chain1)/2):nrow(chain1),c(1:(nbeta + length(dmList)),
                                                 (nbeta+length(dmList)+1):
                                                   (nbeta+length(dmList)+3))]
c2 = chain2[floor(nrow(chain2)/2):nrow(chain2),c(1:(nbeta + length(dmList)),
                                                 (nbeta+length(dmList)+1):
                                                   (nbeta+length(dmList)+3))]
c3 = chain3[floor(nrow(chain3)/2):nrow(chain3),c(1:(nbeta + length(dmList)),
                                                 (nbeta+length(dmList)+1):
                                                   (nbeta+length(dmList)+3))]

c1$gamma_ei = 1-exp(-c1$gamma_ei)
c1$gamma_ir = 1-exp(-c1$gamma_ir)
c2$gamma_ei = 1-exp(-c2$gamma_ei)
c2$gamma_ir = 1-exp(-c2$gamma_ir)
c3$gamma_ei = 1-exp(-c3$gamma_ei)
c3$gamma_ir = 1-exp(-c3$gamma_ir)
{
if (modelDF != 0)
{
  colnames(c1) = c("Guinea Intercept", "Liberia Intercept", 
                   "Sierra Leone Intercept", 
                   paste("Time component ", (1:(nbeta-ncol(X))), sep = ""),
                   "Overdispersion Precision",
                   paste("Spatial Dependence Parameter", 1:length(dmList)),
                   "E to I probability", 
                   "I to R probability")
}
else
{
      colnames(c1) = c("Guinea Intercept", "Liberia Intercept", 
                   "Sierra Leone Intercept",
                   "Overdispersion Precision",
                   paste("Spatial Dependence Parameter", 1:length(dmList)),
                   "E to I probability", 
                   "I to R probability")
}
}
colnames(c2) = colnames(c1)
colnames(c3) = colnames(c1)

mcl = mcmc.list(as.mcmc(c1), 
                as.mcmc(c2),
                as.mcmc(c3))
summary(mcl)

## R0 stuff

R0_list = chains[[2]]$R0




figure10 = function(R0_list, type)
{
  r0.ylim = c(min(R0_list$LB), max(R0_list$UB))
  par(mfrow = c(2,2))
  plotR0 = function(main, idx)
  {
    plot(rptDate[1:(length(rptDate)-1)], R0_list$mean[1:(length(rptDate)-1),idx] , type = "l", xlab = "Date",
         ylab = expression('R'[0]),
         main = main, 
         ylim = r0.ylim, lwd = 2)
    lines(rptDate[1:(length(rptDate)-1)], R0_list$LB[1:(length(rptDate)-1),idx], lty = 2)
    lines(rptDate[1:(length(rptDate)-1)], R0_list$UB[1:(length(rptDate)-1),idx], lty = 2)
    abline(h=seq(0, 50, 0.5), lty=2, col="lightgrey")
    abline(h = 1.0, col = "blue", lwd = 1.5, lty = 2)
  }
  plotR0(paste("Guinea ",type, "R0",sep=""), 1)
  plotR0(paste("Liberia ", type, "R0",sep=""),2)
  plotR0(paste("Sierra Leone ", type,"R0",sep=""), 3)
}

# Guinea, Liberia, Sierra Leone

getMeanAndCI = function(loc,tpt,baseStr="I_")
{
    vec = chain1[[paste(baseStr, loc, "_", tpt, sep = "")]]
    vec = vec[floor(length(vec)/2):length(vec)]
    return(c(mean(vec), quantile(vec, probs = c(0.05, 0.95))))
}

Guinea.I.Est = sapply(0:(nrow(I_star)- 1), getMeanAndCI, loc=0)
Liberia.I.Est = sapply(0:(nrow(I_star)- 1), getMeanAndCI, loc=1)
SierraLeone.I.Est = sapply(0:(nrow(I_star)- 1), getMeanAndCI, loc=2)

# Declare prediction functions
predictEpidemic = function(beta.pred, 
                           X.pred,
                           gamma.ei,
                           gamma.ir,
                           S0,
                           E0,
                           I0,
                           R0,
                           rho,
                           offsets.pred)
{
    N = (S0+E0+I0+R0)
    offsets.pred=c(offsets.pred,1)
    p_se_components = matrix(exp(X.pred %*% beta.pred), ncol=length(S0))
    p_se = matrix(0, ncol = length(S0), nrow = nrow(p_se_components))
    p_ei = 1-exp(-gamma.ei*offsets.pred)
    p_ir = 1-exp(-gamma.ir*offsets.pred)
    S_star = matrix(0, ncol=length(S0),nrow = nrow(p_se_components))
    E_star = matrix(0, ncol=length(S0),nrow = nrow(p_se_components))
    I_star = matrix(0, ncol=length(S0),nrow = nrow(p_se_components))
    R_star = matrix(0, ncol=length(S0),nrow = nrow(p_se_components))
    S = matrix(0, ncol=length(S0),nrow = nrow(p_se_components))
    E = matrix(0, ncol=length(S0),nrow = nrow(p_se_components))
    I = matrix(0, ncol=length(S0),nrow = nrow(p_se_components))
    R = matrix(0, ncol=length(S0),nrow = nrow(p_se_components))
    S[1,] = S0
    E[1,] = E0
    I[1,] = I0
    R[1,] = R0
    S_star[1,] = rbinom(rep(1, length(S0)), R0, 0)
    p_se[1,] = I[1,]/N*p_se_components[1,]
    for (i in 1:length(dmList))
    {
      p_se[1,] = p_se[1,] + rho[i]*(dmList[[i]] %*% (I[1,]/N*p_se_components[1,]))
    }
    p_se[1,] = 1-exp(-offsets.pred[1]*(p_se[1,]))
    
    E_star[1,] = rbinom(rep(1, length(S0)), S0, p_se[1,])
    I_star[1,] = rbinom(rep(1, length(S0)), E0, p_ei[1])
    R_star[1,] = rbinom(rep(1, length(S0)), I0, p_ir[1])
    
    for (i in 2:nrow(S))
    {
    
      S[i,] = S[i-1,] + S_star[i-1,] - E_star[i-1,]
      E[i,] = E[i-1,] + E_star[i-1,] - I_star[i-1,]
      I[i,] = I[i-1,] + I_star[i-1,] - R_star[i-1,]
      R[i,] = R[i-1,] + R_star[i-1,] - S_star[i-1,]
      
      p_se[i,] = I[i,]/N*p_se_components[i,]
      for (j in 1:length(dmList))
      {
        p_se[i,] = p_se[i,] + rho[j]*(dmList[[j]] %*% (I[i,]/N*p_se_components[i,]))
      }
      p_se[i,] = 1-exp(-offsets.pred[i]*(p_se[i,]))
    
      
      S_star[i,] = rbinom(rep(1, length(S0)), R[i,], 0)
      E_star[i,] = rbinom(rep(1, length(S0)), S[i,], p_se[i,])
      I_star[i,] = rbinom(rep(1, length(S0)), E[i,], p_ei[i])
      R_star[i,] = rbinom(rep(1, length(S0)), I[i,], p_ir[i])
    }
    return(list(S=S,E=E,I=I,R=R,
                S_star=S_star,E_star=E_star,
                I_star=I_star,R_star=R_star,
                p_se=p_se,p_ei=p_ei,p_ir=p_ir))
}


predict.i = function(i)
{
  dataRow = chain1[i,]
  rho = rep(0, length(dmList))
  for (i in 1:length(dmList))
  {
    rho[i] = dataRow[[paste("rho_", i-1, sep = "")]]
  }
  beta = rep(0, modelDF+ncol(X))
  for (i in 0:(modelDF+ncol(X) -1))
  {
    beta[i+1] = dataRow[[paste("BetaP_SE_", i, sep = "")]]
  }
   
  S0 = c(dataRow[[paste("S_0_", maxIdx-1, sep = "")]],
         dataRow[[paste("S_1_", maxIdx-1, sep = "")]],
         dataRow[[paste("S_2_", maxIdx-1, sep = "")]],
         dataRow[[paste("S_3_", maxIdx-1, sep = "")]])
  E0 = c(dataRow[[paste("E_0_", maxIdx-1, sep = "")]],
         dataRow[[paste("E_1_", maxIdx-1, sep = "")]],
         dataRow[[paste("E_2_", maxIdx-1, sep = "")]],
         dataRow[[paste("E_3_", maxIdx-1, sep = "")]])
  I0 = c(dataRow[[paste("I_0_", maxIdx-1, sep = "")]],
         dataRow[[paste("I_1_", maxIdx-1, sep = "")]],
         dataRow[[paste("I_2_", maxIdx-1, sep = "")]],
         dataRow[[paste("I_3_", maxIdx-1, sep = "")]])
  R0 = c(dataRow[[paste("R_0_", maxIdx-1, sep = "")]],
         dataRow[[paste("R_1_", maxIdx-1, sep = "")]],
         dataRow[[paste("R_2_", maxIdx-1, sep = "")]],
         dataRow[[paste("R_3_", maxIdx-1, sep = "")]])
  
  
  return(predictEpidemic(beta,  
                         X.pred,
                         dataRow$gamma_ei,
                         dataRow$gamma_ir,
                         S0,
                         E0,
                         I0,
                         R0,
                         rho,
                         offset.pred
                         ))
}

preds = lapply((nrow(chain1) - floor(nrow(chain1)/2)):
                  nrow(chain1), predict.i)


pred.dates = c(rptDate[(which.max(rptDate))],
               rptDate[(which.max(rptDate))] + seq(2,pred.days-2,2))
pred.xlim = c(min(rptDate), max(pred.dates))
lastIdx = nrow(I_star)
Guinea.Pred = preds[[1]]$I[,1]
Liberia.Pred = preds[[1]]$I[,2]
SierraLeone.Pred = preds[[1]]$I[,3]

breakpoint = mean(c(max(rptDate), min(pred.dates)))

for (predIdx in 2:length(preds))
{
   Guinea.Pred = rbind(Guinea.Pred, preds[[predIdx]]$I[,1])
   Liberia.Pred = rbind(Liberia.Pred, preds[[predIdx]]$I[,2])
   SierraLeone.Pred = rbind(SierraLeone.Pred, preds[[predIdx]]$I[,3])
}

Guinea.mean = apply(Guinea.Pred, 2, mean)
Liberia.mean = apply(Liberia.Pred, 2, mean)
SierraLeone.mean = apply(SierraLeone.Pred, 2, mean)


Guinea.LB = apply(Guinea.Pred, 2, quantile, probs = c(0.05))
Guinea.UB = apply(Guinea.Pred, 2, quantile, probs = c(0.95))

Liberia.LB = apply(Liberia.Pred, 2, quantile, probs = c(0.05))
Liberia.UB = apply(Liberia.Pred, 2, quantile, probs = c(0.95))

SierraLeone.LB = apply(SierraLeone.Pred, 2, quantile, probs = c(0.05))
SierraLeone.UB = apply(SierraLeone.Pred, 2, quantile, probs = c(0.95))

maxI = max(c(max(c(Guinea.I.Est, Liberia.I.Est, SierraLeone.I.Est)), Guinea.UB, Liberia.UB, SierraLeone.UB))

est.idx = seq(1, length(Guinea.I.Est[1,]), 2)
pred.table1 = cbind(Guinea.I.Est[1,], 
                    Liberia.I.Est[1,],
                    SierraLeone.I.Est[1,]
                    )[est.idx,]
pred.table2 = cbind(Guinea.mean, 
                    Liberia.mean,
                    SierraLeone.mean)
pred.table = rbind(pred.table1, pred.table2)
rownames(pred.table) = paste("", c(as.character(rptDate)[est.idx], as.character(pred.dates)),
                                          sep = "")
rownames(pred.table) = paste(rownames(pred.table), "&nbsp;", sep = "")
colnames(pred.table) = c("Guinea", 
                         "Liberia", 
                         "Sierra Leone")


figure11 = function()
{
  
  ## Guinea 
  par(mfrow = c(2,2))
  plot(rptDate, Guinea.I.Est[1,], ylim = c(0, maxI), xlim = pred.xlim,
       main = "Guinea Estimated Epidemic Size\n 90% Credible Interval",
       type = "l", lwd = 2, ylab = "Infectious Count", xlab = "Date")
  abline(h = seq(0,1000000,5000), lty = 2, col = "lightgrey")
  lines(rptDate, Guinea.I.Est[1,], lty = 2)
  lines(rptDate, Guinea.I.Est[2,], lty = 2)
  lines(rptDate, Guinea.I.Est[3,], lty = 2)
  
  lines(pred.dates,Guinea.mean, 
          lty=1, col = "black", lwd = 1)
  lines(pred.dates,Guinea.LB, 
          lty=2, col = "black", lwd = 1)
  lines(pred.dates,Guinea.UB, 
          lty=2, col = "black", lwd = 1)
  abline(v = breakpoint, lty = 3, col= "lightgrey")
  
  ## Liberia 
  plot(rptDate, Liberia.I.Est[1,], ylim = c(0, maxI),  xlim = pred.xlim,
       main = "Liberia Estimated Epidemic Size\n 90% Credible Interval",
       type = "l", lwd = 2, col = "blue", ylab = "Infectious Count", 
       xlab = "Date")
  abline(h = seq(0,1000000,5000), lty = 2, col = "lightgrey")
  lines(rptDate, Liberia.I.Est[1,], lty = 2, col = "blue")
  lines(rptDate, Liberia.I.Est[2,], lty = 2, col = "blue")
  lines(rptDate, Liberia.I.Est[3,], lty = 2, col = "blue")
  
  lines(pred.dates,Liberia.mean, 
          lty=1, col = "blue", lwd = 1)
  lines(pred.dates,Liberia.LB, 
          lty=2, col = "blue", lwd = 1)
  lines(pred.dates,Liberia.UB, 
          lty=2, col = "blue", lwd = 1)
  abline(v = breakpoint, lty = 3, col= "lightgrey")
  
  ## Sierra Leone
  plot(rptDate, SierraLeone.I.Est[1,], ylim = c(0, maxI),  xlim = pred.xlim,
       main = "Sierra Leone Estimated Epidemic Size\n 90% Credible Interval",
       type = "l", lwd = 2, col = "red",ylab = "Infectious Count", 
       xlab = "Date")
  abline(h = seq(0,1000000,5000), lty = 2, col = "lightgrey")
  lines(rptDate, SierraLeone.I.Est[1,], lty = 2, col = "red")
  lines(rptDate, SierraLeone.I.Est[2,], lty = 2, col = "red")
  lines(rptDate, SierraLeone.I.Est[3,], lty = 2, col ="red")
  
  lines(pred.dates,SierraLeone.mean, 
          lty=1, col = "red", lwd = 1)
  lines(pred.dates,SierraLeone.LB, 
          lty=2, col = "red", lwd = 1)
  lines(pred.dates,SierraLeone.UB, 
          lty=2, col = "red", lwd = 1)
  abline(v = breakpoint, lty = 3, col= "lightgrey")

}


figure11_5 = function()
{
  
  ## Guinea 
  par(mfrow = c(2,2))
  plot(rptDate, Guinea.I.Est[1,] + 1, ylim = c(1, maxI), xlim = pred.xlim,
       main = "Guinea Estimated Epidemic Size\n 90% Credible Interval (log scale)",
       type = "l", lwd = 2, ylab = "Infectious Count", xlab = "Date", log ="y")
  abline(h = 10^seq(0,100), lty = 2, col = "lightgrey")
  lines(rptDate, Guinea.I.Est[1,] + 1, lty = 2)
  lines(rptDate, Guinea.I.Est[2,] + 1, lty = 2)
  lines(rptDate, Guinea.I.Est[3,] + 1, lty = 2)
  
  lines(pred.dates,Guinea.mean + 1, 
          lty=1, col = "black", lwd = 1)
  lines(pred.dates,Guinea.LB + 1, 
          lty=2, col = "black", lwd = 1)
  lines(pred.dates,Guinea.UB + 1, 
          lty=2, col = "black", lwd = 1)
  abline(v = breakpoint, lty = 3, col= "lightgrey")
  
  ## Liberia 
  plot(rptDate, Liberia.I.Est[1,] + 1, ylim = c(1, maxI),  xlim = pred.xlim,
       main = "Liberia Estimated Epidemic Size\n 90% Credible Interval (log scale)",
       type = "l", lwd = 2, col = "blue", ylab = "Infectious Count", 
       xlab = "Date", log ="y")
  abline(h = 10^seq(0,100), lty = 2, col = "lightgrey")
  lines(rptDate, Liberia.I.Est[1,] + 1, lty = 2, col = "blue")
  lines(rptDate, Liberia.I.Est[2,] + 1, lty = 2, col = "blue")
  lines(rptDate, Liberia.I.Est[3,] + 1, lty = 2, col = "blue")
  
  lines(pred.dates,Liberia.mean + 1, 
          lty=1, col = "blue", lwd = 1)
  lines(pred.dates,Liberia.LB + 1, 
          lty=2, col = "blue", lwd = 1)
  lines(pred.dates,Liberia.UB + 1, 
          lty=2, col = "blue", lwd = 1)
  abline(v = breakpoint, lty = 3, col= "lightgrey")
  
  ## Sierra Leone
  plot(rptDate, SierraLeone.I.Est[1,] + 1, ylim = c(1, maxI),  xlim = pred.xlim,
       main = "Sierra Leone Estimated Epidemic Size\n 90% Credible Interval (log scale)",
       type = "l", lwd = 2, col = "red",ylab = "Infectious Count", 
       xlab = "Date", log ="y")
  abline(h = 10^seq(0,100), lty = 2, col = "lightgrey")
  lines(rptDate, SierraLeone.I.Est[1,] + 1, lty = 2, col = "red")
  lines(rptDate, SierraLeone.I.Est[2,] + 1, lty = 2, col = "red")
  lines(rptDate, SierraLeone.I.Est[3,] + 1, lty = 2, col ="red")
  
  lines(pred.dates,SierraLeone.mean + 1, 
          lty=1, col = "red", lwd = 1)
  lines(pred.dates,SierraLeone.LB + 1, 
          lty=2, col = "red", lwd = 1)
  lines(pred.dates,SierraLeone.UB + 1, 
          lty=2, col = "red", lwd = 1)
  abline(v = breakpoint, lty = 3, col= "lightgrey")

}



end.rcode-->
</div>
<br/>
<br/>
<h3><a id="analysis-2-convergence-sect" class="anchor">Convergence</a></h3>
<p>As this is a Bayesian analysis in which the posterior distribution is sampled using MCMC techniques, we really need some
indication that the samplers have indeed converged to the posterior distribution in order to make any inferences about the 
problem at hand. In the code below, we'll read in the MCMC output files created so far, plot the three chains for each of 
several important parameters, and take a look at the Gelman and Rubin convergence diagnostic (which should be close to 1 if the chains have converged.)
</p>
<!--begin.rcode label="PlotFigure8", dpi=150, fig.align='center', echo=FALSE
figure8()
end.rcode-->

<!--begin.rcode label="PlotFigure8_5", dpi=150, fig.align='center', echo=FALSE, fig.width=6, fig.height=3
figure8_5()
end.rcode-->

<!--begin.rcode label="PlotFigure9", dpi=150, fig.align='center', echo=FALSE
figure9()
end.rcode-->

<!--begin.rcode label="PlotFigure9_5", dpi=150, fig.align='center', echo=FALSE, fig.width=6, fig.height=3
figure9_5()
end.rcode-->

<br/>


<a id="analysis-2-r0-sect" class="anchor"><h3>Basic Reproductive Number Calculation</h3></a>


<p>
A common tool for describing the evolution of an epidemic is a quantity known as the basic reproductive numer, the basic reproductive ratio, or one of several other variants on that theme. The basic idea is to quantify how many secondary infections a single infectious individual is expected to cause in a large, fully susceptible population. Naturally, when this ratio exceeds one we expect the epidemic to spread. Conversely, a basic reproductive number less than one indicates that a pathogen is more likely to die out.</p>

<p>
In truth, there is a lot more to "basic reproductive number" calculation, especially given that different authors use different names for the same quantity, and vice versa. Here we present three different versions. First, we introduce a fairly standard
"time varying basic reproductive number". This quantity is based on the intensity process parameter estimates over time, and is described in Lekone and Finkenstadt (2006). Also described in this work is the "effective" reproductive rate, which is the same quantity scaled by the number of susceptibles (almost the same in this case, due to the relatively small infectious fraction). Finally, we introduce our own, tentatively titled "empirical reproductive number". This measure follows actual transmission probabilities through time and looks at the number of secondary 
cases produced, on average, by one of the infectious individuals in a particular location at a particular time point. While still influenced by
the parametric form chosen, this alternative approach to basic reproductive number calculation may more closely reflect population dynamics. 
</p>
<br/><br/>

<!--begin.rcode label="PlotR0Stuff", dpi=150, fig.align='center', echo=FALSE, results='asis'
  figure10(R0_list[["R0"]], " ")
cat("<hr>")
  figure10(R0_list[["effectiveR0"]], "Effective")
cat("<hr>")
  figure10(R0_list[["empiricalR0"]], "Empirical")
end.rcode-->


While the basic reproductive number is a useful quantity to know, it does not directly make any predictions about future epidemic behavior. In order to do that, we need to simulate epidemics  based on the MCMC samples we have obtained and summarize their variability over time. <br/>


<a id="analysis-2-prediction-sect" class="anchor"><h3>Epidemic Prediction</h3></a><br/>

<br/><br/><p> 
Below, we will attempt to predict the course of the epidemic through early fall. 

We must be cautious when making predictions about a chaotic process this far into the future. The intensity function which drives the exposure process is based on simple smooth functions of time, rather than any external information. While this is perfectly adequate for estimation, it may or may not provide good prediction performance. 
</p>

<!--begin.rcode label="Plotfigure11", dpi=150, fig.align='center', echo=FALSE
figure11()
end.rcode-->

It is sometimes helpful to visualize exponential growth on the log scale. 

<!--begin.rcode label="PlotFigure11_5", dpi=150, fig.align='center', echo=FALSE
figure11_5()
end.rcode-->


<br/>
<p>It can also be helpful to take a look at the data in tabular form.</p><br/>


<div class="row">
<div class="col-sm-2"></div>
<div class="col-sm-9">
<h4>Estimated and Predicted number of Infectious Individuals</h4><br/>
<!--begin.rcode label="SavePredTable", results = "asis", echo=FALSE
kable(pred.table, format = "html", digits = 0, align = "c")
end.rcode-->
</div>
</div>
<p>Such data can also be visualized in map form, though the recent surge in predicted cases has the effect of swamping the earlier dynamics:</p>
<br/>
<h4 align=center>Total Infection Size - Estimated and Predicted:</h4>
<div class='container' id ="pred_app" style="position: relative; max-width: 100%; height:100%">
  <div class = "row" ng-controller='rChartsCtrl_pred' >
    <div class="col-sm-3">
      <input id='zoom-map-slider-pred' type='range' min=1 max=
<!--begin.rcode echo=FALSE, results='asis'
cat(numDays.pred)
end.rcode--> 
      ng-model='pred_Day' width=200>
       <span>Day: <span id ="zoom-map-day-counter-pred"></span></span>
    </div>
    <div class="col-sm-1">  <button class="btn btn-mini btn-primary" id="zoom-map-play-pred" type="button">Play</button></div>
    <div class = "col-sm-6"></div>
  </div>
  <div class="row">
    <div id='zoom_map_pred' class='rChart datamaps col-sm-8 col-sm-offset-1' style="position: relative; max-width: 100%; height:100%"></div>  
    <div class="col-sm-3"></div>
  </div>
</div>
<br/>
<br/>
<br/>


<a id = "conclusions-sect" class="anchor"><h3>Conclusions</h3></a>
<br/>
<p>
This epidemic is evolving extremely rapidly. As of 8/12, it looked like the situation in Liberia was set to continue worsening, and that Guinea is at risk of the same (though not to nearly the same degree). On the other hand, the epidemic in Sierra Leone appeared to be leveling off (though not disappearing). As of 8/28, these look like reasonable predictions, however the models appear to have resumed predicting a fairly catastrophic continued spread, especially in liberia. In particular, the models predict that the epidemic will take off in Nigeria, as the countries are assumed in this case to share several intensity parameters. We may hope that this particular simplifying assumption is invalid, however it is not a hopeful sign that WHO predictions are also becoming catastrophic. These models can not anticipate public health interventions and sudden changes in governmental policy and individual behavior, but recent news from the region gives little reason to hope for a swift end to the epidemic. It is more important now than ever to support the efforts of involved governmental and non-governmental organizations like the <a href="http://www.who.int/en/">WHO</a> and <a href="http://www.doctorswithoutborders.org/about-us">MSF</a></p><br/>

<p>
That wraps up the analyses for now. This document will continue to be updated as the epidemic progresses, reflecting new data and perhaps additional analysis techniques. As the document is tracked via source control it will be easy to see how well past predictions held up and how they change in response to new information. Questions and comments can be shared <a href="https://github.com/grantbrown/libspatialSEIR/issues/1">here</a> 
</p><br/>
      
      </div>
    <div class="col-sm-1">
    </div>
  </div>
</div>
    <a id="dummy_anchor" class = "anchor"></a>  
    <script src="./js/jquery.min.js"></script>
    <script src="./bootstrap/js/bootstrap.min.js"></script>
    <script src="./js/d3.v3.min.js"></script>
    <script src="./js/topojson.v1.min.js"></script>
    <script src='./js/handlebars.min.js' type='text/javascript'></script>
    <script src="./js/angular.min.js"></script>
    <script src="./js/datamaps.world.min.js"></script>
    
    <script>
  function rChartsCtrl($scope){
    $scope.Day = 1;
    $scope.$watch('Day', function(newDay){
      zoom.updateChoropleth(alldata[newDay]);
      $("#zoom-map-day-counter").text(dayLabels[newDay]);
    })
  }
    </script>
    <script>
  function rChartsCtrl_pred($scope){
    console.log("PredCalled.");
    $scope.pred_Day = 1;
    $scope.$watch('pred_Day', function(newDay){
      zoom_pred.updateChoropleth(alldata_pred[newDay]);
      $("#zoom-map-day-counter-pred").text(dayLabels[newDay]);
    })
  }
</script>    

<script id='popup-template' type='text/x-handlebars-template'>
</script>

<script>
var alldata = 
<!--begin.rcode echo=FALSE, results="asis"
{cat(toJSON2(outList))}
end.rcode-->


var chartParams={"dom": "zoom_map",
"scope": "world",
"legend":true,
"geographyConfig":{
  "borderColor":"#cccccc",
  "borderWidth":"2px"},
"fills": 
<!--begin.rcode echo=FALSE, results="asis"
cat(toJSON2(fills))
end.rcode-->
,
"data":
<!--begin.rcode echo=FALSE, results="asis"
cat(toJSON2(outList[[1]]))
end.rcode-->
,"setProjection": function( element, options ) {
    var path;
    var projection = d3.geo.equirectangular()
        .center([1, 13])
        .rotate([4.4, 0])
    	  .scale(700)
  		  .translate([element.offsetWidth / 2, element.offsetHeight / 2]);
     
    path = d3.geo.path()
      .projection( projection );
 
    return {path: path, projection: projection};
  }
}

chartParams.element = document.getElementById('zoom_map')
  
  
  var zoom = new Datamap(chartParams);
  
  if (chartParams.labels){
    zoom.labels()
  }
  
  if (chartParams.legend){
    zoom.legend()
  }


</script>
<script type="text/javascript">
var playing_pred=false;

function intervalFunction_pred(slider,counter,sliderVal){
    if (eval(slider.val()) >= eval(slider.attr("max")))
    {
      slider.val(1);
      counter.text(dayLabels[1]);
      zoom_pred.updateChoropleth(alldata_pred[1]);
      playing_pred = false;
      clearInterval(intervalVariable_pred);
      $("#zoom-map-play-pred").text("Play");
    }
    else if (!playing_pred)
    {
      clearInterval(intervalVariable_pred);
      $("#zoom-map-play-pred").text("Play");
    }
    else
    {
      sliderVal = eval(slider.val()) + 1;
      slider.val(sliderVal);
      counter.text(dayLabels[sliderVal]);
      zoom_pred.updateChoropleth(alldata_pred[sliderVal]);
    }
}



$("#zoom-map-play-pred").click(function(){
    var slider = $("#zoom-map-slider-pred");
    var counter = $("#zoom-map-day-counter-pred");
    var sliderVal = 0;
    if (playing_pred)
    {
      playing_pred = false;
    }
    else
    {
      playing_pred = true;
      $("#zoom-map-play-pred").text("Pause");
      intervalVariable_pred = setInterval(function(){intervalFunction_pred(slider,counter,sliderVal)},100);
    }
});
</script>

<script type="text/javascript">
var playing=false;

function intervalFunction(slider,counter,sliderVal){
    if (eval(slider.val()) >= eval(slider.attr("max")))
    {
      console.log("Exit Case 1.");
      slider.val(1);
      counter.text(dayLabels[1]);
      zoom.updateChoropleth(alldata[1]);
      playing = false;
      clearInterval(intervalVariable);
      $("#zoom-map-play").text("Play");
    }
    else if (!playing)
    {
      console.log("Exit Case 2.");
      clearInterval(intervalVariable);
      $("#zoom-map-play").text("Play");
    }
    else
    {
      sliderVal = eval(slider.val()) + 1;
      console.log("Run Case: " + sliderVal);
      slider.val(sliderVal);
      counter.text(dayLabels[sliderVal]);
      zoom.updateChoropleth(alldata[sliderVal]);
    }
}



$("#zoom-map-play").click(function(){
    var slider = $("#zoom-map-slider");
    var counter = $("#zoom-map-day-counter");
    var sliderVal = 0;
    if (playing)
    {
      playing = false;
    }
    else
    {
      playing = true;
      $("#zoom-map-play").text("Pause");
      intervalVariable = setInterval(function(){intervalFunction(slider,counter,sliderVal)},100);
    }
});
</script>


<script>
var alldata_pred = 
<!--begin.rcode echo=FALSE, results="asis"

# pred  means

Guinea.pred.vec = c(Guinea.I.Est[1,], Guinea.mean[2:length(Guinea.mean)])
Liberia.pred.vec = c(Liberia.I.Est[1,], Liberia.mean[2:length(Guinea.mean)]) 
SierraLeone.pred.vec = c(SierraLeone.I.Est[1,], SierraLeone.mean[2:length(Guinea.mean)])


x = c(rptDate, pred.dates[2:length(Guinea.mean)]) - min(rptDate) 
guinea.interp.pred = approx(x,Guinea.pred.vec,xout = 0:max(x))
liberia.interp.pred = approx(x,Liberia.pred.vec,xout = 0:max(x))
sierraleone.interp.pred = approx(x,SierraLeone.pred.vec,xout = 0:max(x))

interpMatrix = cbind(guinea.interp.pred$y, liberia.interp.pred$y,
                     sierraleone.interp.pred$y)


cutvals = cut(interpMatrix, breaks = 9)
interpMatrix.cut = matrix(as.numeric(cutvals), nrow = nrow(interpMatrix))
upperVals = as.numeric(lapply(strsplit(c(gsub("[(]", "", gsub("]", "", unique(as.character(levels(cutvals)))))), ","), function(x){return(x[2])}))
upperVals = round(upperVals[order(upperVals)],0)

hcol = c("#ffffef", "#fff7bf", "#fee39f", "#fec45f", "#fe993f", "#ec702f", "#cc4c1f", "#993402", "#662520")
color.palette = c(hcol[1],hcol)
fills.pred = setNames(color.palette, c("defaultFill", paste("lt", upperVals, sep = "")))

# GIN, LBR, SLE
outList.pred = list()
for (tpt in min(x):max(x))
{
    outList.pred[[as.character(tpt+1)]] = list("GIN" = list("fillKey"=factor(paste("lt", upperVals[interpMatrix.cut[tpt+1,1]], sep =""), 
                                                        levels = names(fills.pred))),
                                          "LBR" = list("fillKey"=factor(paste("lt", upperVals[interpMatrix.cut[tpt+1,2]], sep = ""), 
                                                        levels = names(fills.pred))),
                                          "SLE" = list("fillKey"=factor(paste("lt",upperVals[interpMatrix.cut[tpt+1,3]], sep = ""), 
                                                        levels = names(fills.pred)))
                                          )
}

{cat(toJSON2(outList.pred))}
end.rcode-->


var dayLabels=
<!--begin.rcode echo=FALSE, results="asis"
dayLabels = as.list(as.character((min(rptDate) + 0:(numDays.pred))))
names(dayLabels) = 1:length(dayLabels)
cat(toJSON2(dayLabels))
cat(";")
end.rcode-->
var chartParams_pred={"dom": "zoom_map_pred",
"scope": "world",
"legend":true,
"geographyConfig":{
  "borderColor":"#cccccc",
  "borderWidth":"2px"},
"fills": 
<!--begin.rcode echo=FALSE, results="asis"
cat(toJSON2(fills.pred))
end.rcode-->
,
"data":
<!--begin.rcode echo=FALSE, results="asis"
cat(toJSON2(outList.pred[[1]]))
end.rcode-->
,"setProjection": function( element, options ) {
    var path;
    var projection = d3.geo.equirectangular()
        .center([1, 13])
        .rotate([4.4, 0])
    	  .scale(700)
  		  .translate([element.offsetWidth / 2, element.offsetHeight / 2]);
     
    path = d3.geo.path()
      .projection( projection );
 
    return {path: path, projection: projection};
  }
}

chartParams_pred.element = document.getElementById('zoom_map_pred')

var zoom_pred = new Datamap(chartParams_pred);

if (chartParams_pred.labels){
  zoom_pred.labels()
}

if (chartParams_pred.legend){
  zoom_pred.legend()
}
</script>
<script type="text/javascript">
  var data_app = angular.module('data_app', []);
  var pred_app = angular.module('pred_app', []);
  angular.bootstrap(document.getElementById("pred_app"), ['data_app']);
</script>

<script type="text/javascript">
      $(document).ready(function(){
        $("table").addClass("table-striped");
        $("table").addClass("table-bordered");
      });

      $(".code-button").click(function(){
          $(this).next().animate({
            opacity: 1,
            left: "+=100",
            height: "toggle"
          }, 100, function() {
          });
      });
      
    </script>
  
  </body>
</html>
